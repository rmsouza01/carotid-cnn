{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified U-net with Time Context - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate\n",
    "from keras.layers import UpSampling2D, Dropout \n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import sys\n",
    "import time\n",
    "import nibabel as nib\n",
    "np.random.seed(302)\n",
    "\n",
    "# CNN metrics for segmentation problems\n",
    "smooth = 1. #CNN dice coefficient smooth\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    ''' Metric used for CNN training'''\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    ''' Loss function'''\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def get_unet_mod(patch_size = (None,None),learning_rate = 1e-5):\n",
    "    ''' Get U-Net model with gaussian noise and dropout'''\n",
    "    \n",
    "    gaussian_noise_std = 0.025\n",
    "    dropout = 0.25\n",
    "    \n",
    "    inputs = Input((patch_size[0], patch_size[1],3))\n",
    "    input_with_noise = GaussianNoise(gaussian_noise_std)(inputs)    \n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_with_noise)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(dropout)(pool4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4],axis=-1)\n",
    "    up6 = Dropout(dropout)(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3],axis=-1)\n",
    "    up7 = Dropout(dropout)(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2],axis=-1)\n",
    "    up8 = Dropout(dropout)(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=-1)\n",
    "    up9 = Dropout(dropout)(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    opt = Adam(lr=learning_rate, decay = 1e-6)\n",
    "    model.compile(optimizer= opt,loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patches_path = \"/media/roberto/DATA/GDrive/Jupyter-Scripts/Carotid-CNN/Patches\"\n",
    "prefixes = [\"Kmd\",\"Djm\",\"ARS\",\"AS\",\"BAB\",\"ETB\",\"IC\",\"LKS\",\"MBT\",\"MK\",\"RAB\",\"SNL\"]\n",
    "patch_files = [f for f in os.listdir(patches_path) if f.endswith(\"_orig.npy\") or f.endswith(\"_orig2.npy\")]\n",
    "\n",
    "for fold in xrange(1,12):\n",
    "    patches = np.zeros((1,64,64,3))\n",
    "    labels = np.zeros((1,64,64,1))\n",
    "    for ii in patch_files:\n",
    "        if ii.startswith(prefixes[fold]):\n",
    "            continue\n",
    "        aux_patches = np.load(os.path.join(patches_path,ii))\n",
    "        try:\n",
    "            aux_labels = np.load(os.path.join(patches_path,ii[:-9]+\"_seg.npy\"))[:,:,:,np.newaxis]\n",
    "        except:\n",
    "            aux_labels = np.load(os.path.join(patches_path,ii[:-10]+\"_seg2.npy\"))[:,:,:,np.newaxis]\n",
    "        patches = np.concatenate((patches,aux_patches),axis = 0)\n",
    "        labels = np.concatenate((labels,aux_labels),axis = 0)\n",
    "\n",
    "    patches = patches[1:] \n",
    "    labels = labels[1:]\n",
    "    indexes = np.arange(patches.shape[0],dtype = np.int32)\n",
    "    np.random.shuffle(indexes)\n",
    "    patches = patches[indexes]\n",
    "    labels = labels[indexes]\n",
    "\n",
    "    train01 = patches[:-5500]\n",
    "    labels01 = labels[:-5500]\n",
    "\n",
    "    val01 = patches[-5500:]\n",
    "    labels_val01 = labels[-5500:]\n",
    "    model_name = \"carotid_unet_tr_cnn\"\n",
    "    mean = np.mean(train01)  \n",
    "    std = np.std(train01)\n",
    "\n",
    "    train01 -= mean\n",
    "    train01 /= std\n",
    "\n",
    "    val01-= mean\n",
    "    val01/= std\n",
    "    print train01.shape\n",
    "\n",
    "    np.save(prefixes[fold]+\".npy\",np.array([mean,std]))\n",
    "    # Early stopping callback to shut down training after 10 epochs with no improvement\n",
    "    earlyStopping = EarlyStopping(monitor='val_dice_coef',\n",
    "                                           patience=15, \n",
    "                                           verbose=1, mode='auto')\n",
    "\n",
    "    # Checkpoint callback to save model after each improvement along the epochs\n",
    "    checkpoint = ModelCheckpoint(prefixes[fold] + model_name + '.hdf5', mode = 'max', monitor='val_dice_coef'\n",
    "                                 ,verbose=0, save_best_only=True, save_weights_only = True)\n",
    "\n",
    "\n",
    "    model = get_unet_mod(patch_size = (64,64))\n",
    "    #print model.summary()\n",
    "\n",
    "    seed = 905\n",
    "    image_datagen = ImageDataGenerator(\n",
    "            rotation_range=30,\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.15,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='constant',\n",
    "            cval = 0)\n",
    "\n",
    "    mask_datagen = ImageDataGenerator(\n",
    "            rotation_range=30,\n",
    "            width_shift_range=0.05,\n",
    "            height_shift_range=0.05,\n",
    "            shear_range=0.15,\n",
    "            zoom_range=0.15,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='constant',\n",
    "            cval = 0)\n",
    "\n",
    "\n",
    "\n",
    "    image_datagen.fit(train01, augment=True, seed=seed)\n",
    "    mask_datagen.fit(labels01, augment=True, seed=seed)\n",
    "\n",
    "    image_generator = image_datagen.flow(train01,batch_size = 32,seed = seed)\n",
    "    mask_generator = mask_datagen.flow(labels01,batch_size = 32,seed = seed)\n",
    "\n",
    "\n",
    "    # function to merge generators\n",
    "    def combine_generator(gen1, gen2):\n",
    "        while True:\n",
    "            yield(gen1.next(), gen2.next())\n",
    "\n",
    "    # combine generators into one which yields image and masks\n",
    "    combined = combine_generator(image_generator, mask_generator)\n",
    "\n",
    "    hist = model.fit_generator(combined,\n",
    "                     epochs=100,\n",
    "                     steps_per_epoch=train01.shape[0] / 32,\n",
    "                     verbose=1,\n",
    "                     validation_data= (val01,labels_val01),\n",
    "                     callbacks=[checkpoint,earlyStopping])   \n",
    "\n",
    "    #Load the best_model during training\n",
    "    best_model = get_unet_mod(learning_rate =  5e-6)\n",
    "    best_model.load_weights(prefixes[fold] + model_name + '.hdf5')\n",
    "\n",
    "    hist = best_model.fit_generator(combined,\n",
    "                     epochs=100,\n",
    "                     steps_per_epoch=train01.shape[0] / 32,\n",
    "                     verbose=1,\n",
    "                     validation_data= (val01,labels_val01),\n",
    "                     callbacks=[checkpoint,earlyStopping])     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
